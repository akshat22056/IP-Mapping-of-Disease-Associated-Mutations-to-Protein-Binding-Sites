{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4vjMenBkL2iD",
        "outputId": "e9c051cd-af65-4f1e-d770-00c1611d819f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing 18633 unique genes...\n",
            "\n",
            "Processed 18633 rows in 35.06 seconds\n",
            "Results saved to output_with_uniprot_ids.tsv\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import requests\n",
        "import time\n",
        "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
        "\n",
        "# Cache to store already fetched IDs\n",
        "UNIPROT_CACHE = {}\n",
        "\n",
        "def get_uniprot_ids_batch(gene_batch):\n",
        "    \"\"\"Fetch UniProt IDs for a batch of genes\"\"\"\n",
        "    base_url = \"https://rest.uniprot.org/uniprotkb/search\"\n",
        "    query = ' OR '.join([f'gene_exact:{gene}' for gene in gene_batch])\n",
        "    query += ' AND organism_id:9606 AND reviewed:true'\n",
        "\n",
        "    params = {\n",
        "        'query': query,\n",
        "        'format': 'tsv',\n",
        "        'fields': 'accession,gene_names',\n",
        "        'size': len(gene_batch)\n",
        "    }\n",
        "\n",
        "    try:\n",
        "        response = requests.get(base_url, params=params)\n",
        "        response.raise_for_status()\n",
        "\n",
        "        # Parse response and build mapping\n",
        "        lines = response.text.split('\\n')[1:]  # Skip header\n",
        "        results = {}\n",
        "        for line in lines:\n",
        "            if line.strip():\n",
        "                parts = line.split('\\t')\n",
        "                if len(parts) >= 2:\n",
        "                    uniprot_id, genes = parts[0], parts[1]\n",
        "                    for gene in genes.split():\n",
        "                        results[gene] = uniprot_id\n",
        "        return results\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Batch error: {str(e)}\")\n",
        "        return {}\n",
        "\n",
        "def process_tsv_fast(input_file, output_file, batch_size=100, max_workers=5):\n",
        "    \"\"\"Process TSV file with optimized batch lookups\"\"\"\n",
        "    # Read TSV file\n",
        "    df = pd.read_csv(input_file, sep='\\t')\n",
        "\n",
        "    # Clean gene names\n",
        "    df['GENE_SYMBOL'] = df['GENE_SYMBOL'].str.split(',').str[0].str.strip()\n",
        "\n",
        "    # Get unique genes\n",
        "    unique_genes = df['GENE_SYMBOL'].unique().tolist()\n",
        "    total_genes = len(unique_genes)\n",
        "    print(f\"Processing {total_genes} unique genes...\")\n",
        "\n",
        "    # Process in batches with threading\n",
        "    start_time = time.time()\n",
        "    with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
        "        futures = []\n",
        "        for i in range(0, total_genes, batch_size):\n",
        "            batch = unique_genes[i:i+batch_size]\n",
        "            futures.append(executor.submit(get_uniprot_ids_batch, batch))\n",
        "            time.sleep(0.1)  # Small delay between batch submissions\n",
        "\n",
        "        # Collect results\n",
        "        for future in as_completed(futures):\n",
        "            UNIPROT_CACHE.update(future.result())\n",
        "\n",
        "    # Add UniProt IDs to dataframe\n",
        "    df['UniProt_ID'] = df['GENE_SYMBOL'].map(UNIPROT_CACHE).fillna('Not found')\n",
        "\n",
        "    # Reorder columns\n",
        "    cols = ['UniProt_ID'] + [col for col in df.columns if col != 'UniProt_ID']\n",
        "    df = df[cols]\n",
        "\n",
        "    # Save as TSV\n",
        "    df.to_csv(output_file, sep='\\t', index=False)\n",
        "\n",
        "    elapsed = time.time() - start_time\n",
        "    print(f\"\\nProcessed {len(df)} rows in {elapsed:.2f} seconds\")\n",
        "    print(f\"Results saved to {output_file}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    input_tsv = \"Cosmic_CompleteTargetedScreensMutant_v101_GRCh38_output.tsv\"\n",
        "    output_tsv = \"output_with_uniprot_ids.tsv\"\n",
        "\n",
        "    # Adjust parameters based on your needs:\n",
        "    process_tsv_fast(\n",
        "        input_file=input_tsv,\n",
        "        output_file=output_tsv,\n",
        "        batch_size=100,  # Number of genes per API call\n",
        "        max_workers=5    # Number of concurrent requests\n",
        "    )"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
